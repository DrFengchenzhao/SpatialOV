{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ead70645-98ea-4c07-a3cf-15f46988b05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/data/person/lab/fengcz/conda/envs/squidpy/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-11-21 16:14:15.691444: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-21 16:14:16.426009: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-21 16:14:16.527167: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-21 16:14:16.570122: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-21 16:14:17.058917: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-21 16:14:21.915637: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scanpy==1.9.3 anndata==0.9.2 umap==0.5.3 numpy==1.25.2 scipy==1.11.4 pandas==1.3.5 scikit-learn==1.2.1 statsmodels==0.14.0 python-igraph==0.10.2 pynndescent==0.5.7\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import anndata as an\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "\n",
    "sc.set_figure_params(dpi_save=300,color_map = 'viridis_r')\n",
    "sc.settings.verbosity = 1\n",
    "sc.logging.print_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86ccff3d-49b0-46c3-8b34-254d4b12f306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_clone_prob(adata):\n",
    "    # Inputs: cnv_matrix (spots x features), initial_clone_labels (spots), use_t = False\n",
    "\n",
    "    cnv_matrix = adata.obsm['X_pca']\n",
    "    initial_clone_labels = adata.obs['Spatial_clone'].values\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from scipy.stats import multivariate_normal\n",
    "    \n",
    "    # initial_clone_labels: array of strings, e.g. [\"Clone1\",\"Clone2\",\"Clone1\",...]\n",
    "    \n",
    "    #  Encode string labels â†’ numeric indices for array operations\n",
    "    unique_labels = np.unique(initial_clone_labels)\n",
    "    label_to_index = {lab: i for i, lab in enumerate(unique_labels)}\n",
    "    index_to_label = {i: lab for lab, i in label_to_index.items()}\n",
    "    \n",
    "    clone_ids = np.array([label_to_index[lab] for lab in initial_clone_labels])\n",
    "    K = len(unique_labels)\n",
    "    \n",
    "    #  Compute centroids per clone\n",
    "    centroids = np.vstack([\n",
    "        cnv_matrix[clone_ids == k].mean(axis=0)\n",
    "        for k in range(K)\n",
    "    ])\n",
    "    \n",
    "    #  Estimate covariance (pooled diagonal with ridge)\n",
    "    residuals = np.vstack([\n",
    "        cnv_matrix[clone_ids == k] - centroids[k]\n",
    "        for k in range(K)\n",
    "    ])\n",
    "    cov = np.cov(residuals, rowvar=False)\n",
    "    eps = 1e-6 * np.mean(np.diag(cov))\n",
    "    cov_shrink = np.diag(np.diag(cov) + eps)\n",
    "    \n",
    "    #  Compute posterior probabilities\n",
    "    log_likelihoods = np.zeros((cnv_matrix.shape[0], K))\n",
    "    for k in range(K):\n",
    "        log_likelihoods[:, k] = multivariate_normal.logpdf(\n",
    "            cnv_matrix, mean=centroids[k], cov=cov_shrink\n",
    "        )\n",
    "    \n",
    "    priors = np.array([(clone_ids == k).mean() for k in range(K)])\n",
    "    log_post = log_likelihoods + np.log(priors + 1e-12)\n",
    "    log_post -= log_post.max(axis=1, keepdims=True)\n",
    "    post = np.exp(log_post)\n",
    "    post = post / post.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    # Probability for the clone originally assigned to each spot\n",
    "    original_clone_prob = post[np.arange(len(clone_ids)), clone_ids]\n",
    "    \n",
    "    # Max probability across all clones (for comparison)\n",
    "    top_probs = post.max(axis=1)\n",
    "    \n",
    "    # New assigned clone (highest posterior)\n",
    "    assigned_numeric = post.argmax(axis=1)\n",
    "    assigned_labels = np.array([index_to_label[i] for i in assigned_numeric])\n",
    "    \n",
    "    # Shannon entropy for uncertainty\n",
    "    entropy = -np.sum(post * np.log(post + 1e-12), axis=1)\n",
    "\n",
    "\n",
    "    adata.obs['initial_clone_label'] = initial_clone_labels\n",
    "    adata.obs['assigned_clone'] = assigned_labels\n",
    "    adata.obs['prob_initial_clone'] = original_clone_prob\n",
    "    adata.obs['prob_assigned_clone'] = top_probs\n",
    "    adata.obs['entropy'] = entropy\n",
    "    adata.obs['prob_clone1'] = pd.DataFrame(post).iloc[:,label_to_index['clone_1']].values\n",
    "\n",
    "    return(adata.obs)\n",
    "    # return(post)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81817f82-fb98-437a-b16f-27aea86a46bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_006 = sc.read('./window100/P6_YF_1/clone_assigned.h5ad')\n",
    "prob = calculate_clone_prob(adata_006)\n",
    "prob.to_csv('posterior_probability/OV006.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a095c113-fa2f-400d-a027-fd6d3a0642e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "squidpy",
   "language": "python",
   "name": "squidpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
